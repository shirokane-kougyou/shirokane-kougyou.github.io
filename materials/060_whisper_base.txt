'では今回のお題は最近話題のステーブルディフィュージョンに並んでというか続きてというかで話題のビスパーさんのお話の技術解析を同じく広化先生からお願いしたいと思いますよろしくお願いしますそうですねちょうどステーブルディフィージョンとが早ったその週とか次の週とかにまたオート名相から今度は音声ですね完成処理ですごい制度反化性もかなり高いってビスパーでモモデルがオープンAIから公開されたのでこちらもはい論文によるんで少しどんなアルゴリズムでどんな特徴があるのか今回是非話しできればと思いますよろしくお願いしますお願いしますでは早速概要なんですけれどもこちらオープンAIが発表したビスパーっていうモデルというかアルゴリズムというかそういった成果ですねで特徴として608万時間分の音声データたげんよ英語以外にも日本語とかドイツ語とかいろんな68万時間分の大部分は多分英語なんですけど今多様な音声データを学習することで人に引っ適する制度でも制度プラスロバスト性いろんな環境をノイズが乗ってたりそうですねそういったいろんな環境のでもロバストな音声に好きが可能になりましたっていうモデルですでプラスですねこのホームって太様なデータセットを音系にフォーカスするためにモデルが開けてきたですねこちらはシンプルなトランスフォーマーエンコードデーコード開けてくちゃっての使っておりますでプラスメインだとわりと英語で音声聴いてその英語の書き欲しいっていうのがメインなんですけど学生似合わせですねこの英語音声からテキスト英語テキスト書き欲しいの他に入力音声の言語の特定だったり他の英語以外にも日本語音声聞いて日本語にテキスト書き欲しいとかも含めていろんなマルチタスクてかついマルチな言語の学習を行っておりますで結果としてですね英語を含む99種類の言語に対して高い性とか安定性で音声の書き欲しいや日本語のプラスですね日本語音声とかを加えて英語の役をのテキストを出るくするみたいなも可能になっているそうですいやーこれはマジで顧客が求めていたものの最終形態がついに来てくれましたねいやそうですねなんか僕もYouTubeとかって結構自動自慢くみたいのあると思うんですけどわりとなんか適当というかそれまあこれが今の限界かなみたいに思う時あるんですけど結構このミスパーウェブでブラザレ使えるでもとかも公開されてなんか僕も試しにポットキャスト収録してますみたいなことを話した時に全員ほとんど完璧に文字を越してくれてなるほどっていう感じでしたねいやーマジすごいなちょっと自分はポットキャストのなんでいやーこれじゃあポットキャストも全部文字を越しできて検索が可能になってルイジとかも取れるようになってもうポットキャストを確かに来たじゃんって思ってたけどでも確かにそれよりYouTubeの字幕付けるっていうその市場の方がでっかいですよね確かに僕がぜひやってほしいですねかなりYouTubeを見ているので確かに確かにだから中身に行きますかどうやって彼らは文字を越しをしているのかそうですねなんですけどその前ですね音声認識これまでどういた研究があったかっていうところで論文で少し触れられていたんでこちらも少し話せればと思いますイントロダクションですねはい他の音声認識論文だとオートマティックスピーチレクグにしようそうですね英語だとそういう風に言われるんですけどこれをこれは行うアプロチというのはもちろんウィスパー以前を取り組まれていました今例えば最近のですねGoogleの出した成果ビッグSSLっていうような成果だと僕はですねウィスパーが68万時間分なのに対してこのGoogleの最近の研究だと100万時間分のラベルなし音声データを使って教師なし学習してその上でこの協の書物データにファインチューニングするっていうのはアプロチも提案されていましたこっちのGoogleの方がデータ量多いんですねそうですね僕もはいウィスパー68万時間ってを過ぎていましたんですけどじゃあなんかそうですねこの教師なしの方で100万時間使って学習したら10万時間使ってもあるっていうふうに書いてありますねまたはファインチューニングによるアプロチで目標データの評価データに対してはSuperhearman人間GoEleveの制度が出ましたよっていうのは報告はあるんですけど一方でそれ以外のデータセットに適用するとちょっとあんまりSuperhearmanって言ってたわりには他のデータに適用するとうまくいかないっていうのはことも報告されているっていうのは言われておりますとなるほどなんでこのウィスパーの時点でも目標としてはできるだけその応用先のデータセットに遺存しないでファインチューニングすようで反化するモデルを獲得したいよねっていうふうに言われていますとでこちらですね今の100万時間っていうのは教師なしの音声だけ音、オーディオだけで学習して目標データにファインチューニングするってアプロチだったんですけど一方ですね教室付きの音声データセットっていうのは大さずがに量が限られていますとでまろん分で話されていたのはきれいな教室付きデータセットだと5000時間くらいでもうちょっとゆるいノイジューな10000教室付きデータセットでも一万時間とか3万時間くらいのものしかないんですよねっていうふうに言われていましたとまあウィスパーではこういった教室付きデータセットともう大なさらにもう大なデータセットのギャップを埋めるって目的で10000教室付き音声データの量もっとスケーラップして結果的に68万時間のタゲンゴのデータセットを作って教師あり学習を行いましたとでこれによって最終的には特定のデータセットのファインチューニングってのお金なずにまっすいろん可能となっていて結果的にすぐれたアンカー性のっていうのを獲得しましたよってふうなえ、ながらざっくり固られていましたそうだったんだちなみに音声でいう教室付きっていうのは本当にその音声データと実際に何に喋られたかっていうテキストが付いてるっていうことなんですよねそうだったはい、思いますねあとはさらにこの回答この音声の何秒から何秒ないだにこのテキストでみたいなも気持ちいてるともっと詳細で学習しやすかったりするのかなと思いますねうんそうかで、なんかテキリ680万時間っていうから教師なしなんだろうなって勝手に思ってたんですけど教師やり教師やりというか弱教室付き音声データって何なんですかねはい、一応あれですね68万時間あ、68万時間で、弱教室付きっていうのは今後ちのち説明するんですけどえっと、何も基本的には音声に対してテキストが紐付いているっていう状態ですねうんうんうんあ、そうもっとけばいいんだなるほどはい基本的にそのペアでウィスパーも学習していくっていう状態ですねすごいなぁデータセット集めてきたんだ作ったのか集めたのかわかんないけどそうですねはい、早速その辺のウィスパーの中身付いてちょっと説明していければと思いますウィスパーの中身ってことでデータセットとモデルのアーキテクチャと学習方法って3つお中に説明していければと思いますまずデータセットですね今回その画像とかでもよくあると思うんですけどまぁ、ボーダーやなデータセットっていうのを確保するためにインターネットから書き起こしあ、テキストの書き起こしが増やされた音声っていうのを収集していますこの音声っていうのはいろんな環境だったり6音設定だったりまわしゃまた、音なだったりもう解きてだったり男性女性っていうことかなって思いますねあとは英語以外にいろんな言語をカバーするように収集していますで、まぁ単純に何も考えずに収集するってだけではなくてプラスですね一部の書き起こしインターネットから収集できる書き起こしっていうのは既存のテキスト書き起こしサービスが増やしたもの創定されますとなのでそれに対して人での書き起こしと機会が自動的に付けた書き起こしラベル教師ですねが混在すると学習にちょっと悪影響があるっていう風に言われているのでそれがヒューリスティックスビッグリマークとか果てなマークだったりカンマーのウムだったり全て面白い面白い面白い面白い面白い面白い面白い面白い面白い面白い面白い面白い面白い面白い面白い面白い面白い面白い面白い個別の笑顔 笑顔手キストその feelings cons靈魂騎郷審柱カンetes本申し抜けてその個人個人階打電気エ practiced特定敵批判ietまたハマ樋木岩馬五花近小浟vi configurations越が同いってこれによって タゲン語を カツーマルチタスクの学習用のデータセットをそうして作成したというふうになっているとのことです学習用には元々コンセー結構時間いろいろバラスキャルともで学習用には最終的に30秒ごとの 音声のクリップに分割して学習に使ったとのことですうんこれって 実際日本語も結構制度いいっていう話が出てくると思うんですけど日本語の教師ありのデータセットって トッカルもってきたんですかねなんか具体的にはアプリンディックスとか見ればあるかもしれないですけどちょっとパッと見は具体的に日本語はここからとかはなかったですねなんかこれ論文に書いてあった時じゃないんですけど結構このロンビスパーの論文読んでいるときに歌のサイトとかって歌ってる内容と歌詞がひもつきられたりするんで 愛情の方しかしたら使えるのかなとちょっと思ったりしましたねなるほど それを面白いですねでデータセットはこういった内容ですねそれに踏まえてモデルのアーキテクチャと学習方法に移りますこのウィスパーではですね まさきほど用意した豊富なデータセットとまるちゲンゴをまるちタスクの学習っていうのに 増加するためにこのモデルのアーキテクチャに関しては 本性からテキストの書き起こしっていうSQL2SQL2の 水論が実行できてデータルをに対してスケールするアーキテクチャとしてシンプルな 延後だでコードアベスのトランスフォーマーを採用しているというふうになっておりますここはわりと 即まで複雑ではないですね延後だの方ではですね もともと音声は発計ですのでこれをログメルステクトログラム 時間かける収発の表現ですねに変換した上で 1時限のコンボリューション1Dとゲルという 活性が完成を通した上でこのトランスフォーマーでも一般に使われるポジショナルエンコーディング通してトランスフォーマーエンコーダに入力しますこの辺 スイッケンスとセイクエンスってところで ザックを中には 避け人の本訳のようなゲーストをザックリアに入っているかなと思いますねその上で コードアベスの書きを 順次予測するんですけれども順次予測しますと なので マウンセンに入力して それに対応するディスアーブタイな テキストを予測していきますと シンプルにはその上なんですけどアプラス実際にはですね この話されている オーディオの言語が何なのか絵語だったのか 日本語だったのか だったり 発売用意義のタイムスタンプの予測なども マテキストと求めて トークン系列として扱って全部丸とまとめて 予測対処とするということを行っているようですなるほど これ 実際にツイッターとかで 試した人たちが上げてたんですけどこれは日本語だよって 教えずにやってたのに 普通に日本語として強くちゃんとしてくれてるみたいなやつはそもそもモデルが学習している中に この今 学習で見せられているものが日本語であるっていうことも 振きくるめて 学習してるってことなんですねそういう人はい その通りですねすごいな これ というかあれか 学習の時にインプットは音のデータですけど 実際にモデルが学習してるのはメルスペクトログラム だから よく 音声系の人たちが画像出している波打ったモニモニモニモニモみたいな 画像を見せて この画像のこういうエダったら この発音をしてるよっていう テキストを予想するっていう画像からテキストを予想するってことをやってるんですねざっくり言えば そうなりますねはい そしてなんで この辺の全部まとめて 言語の特定とかタイムスタンプとかも 全部トークンとして 経列として トークン経列として正計して トランスソーマーの セイクエスト セイクエストで 学習しちゃうっていうのがうまいところであり トランスソーマーの結構 柔軟で 優秀なところなのかなっていうのを読んでて思ったところですねそうですよね 全部 弾くるめても 学習してってやってるってことですもんねなので モデルのアーキテクチャーと 学習方法もざっくりほとんどこれで以上って形ですね でも もともともデータお68万時間あって多様なので 学習時のデータ カクチャーとかもマロン文ではしていないっていうふうに 書いてありましたと あとはもうほとんど実験結果とディスカッションですね 基本的にはかなり 制度はいいっていうなんか大まかの内容なんですけど やり方としたですね 学習で68万時間 学習していますとでも もともともとも 目標として ファイン中人グ などによらない反化性の見入ってのが目標だったので既存の各評価用データセットの 評価セットを直接 水論して それで評価を行うっていう使用しています評価指標はですね 一般的な音声認識の指標であるワードエラー例と早速した単語系列が 世界とちゃんとマッチしているかっていうのを使っています全部の実験結果は ちょっと活在するんですけど分かりしているところと まず英語の音声認識ですね英語の音声認識だと リブリスピーチっていうデータセットが一般的なようですで このリブリスピーチだけを見るとですね 必ずしもミスパーっていうのは既存のこのリブリスピーチで 教師やりで学習したモデルの制度には読んでいませんんですけども 一方でそれを踏まえて 他のデータセットも含めた平均的な反化性のを見てみましょうデータセットいくつかあるわけですけど ワイスパーで全部評価してみるっていうのと既存の教師やりモデルで リブリスピーチで学習したモデルを可能色のデータセットでも評価してみましょうそれによって 各データセットまたがった平均的な反化性のを見てみましょうっていう扱いだと非常に過ごれた認識性ので 成っていて人の認識性度この論文の中で書かれていたのは 教師やの一人のアレクラドフォードさんっていうのかなり有名な方の認識性度も引っ適しているっていうふうに書かれていますかこれは 教師やの人が同じデータセット聞いて ちゃんと聞きなんですか 認識できたかって いう制度もとってるってことなんですよねそうですね 面白いなるほどなので そうですね やっぱり既存のモデル的はしやりファインチューニングベースのアプローチだとその中人がしたデータセットだと スイパーヒューマンっていうので言われていても他のデータセットも含めた 成のデータになるような言いわれています英語の次に 単元語の音声認識ですねそれでもやっぱりするれた認識性のが確認されましたと面白いのが この学習データ68万時間あってその中に 各言語のデータリオバラ付きがあってやっぱり英語が一番多くて マイナナ言語だと結構少ないものがあるんですけど実際の総観学習データの両と 各言語の学習データの両とその言語のエラーの総観っていうのを見てみるとすごいかなり綺麗に総観が取れました 両対数グラフですがいかなりすぐな総観があって もうやっぱりデータを増やすほどちゃんとエラーレートの制度もスケールしていくよねっていうのがわかってわかったっていう風に報告されていますもうデータリオが正義みたいな世界なんですねそうですね こんななんか綺麗に総観出るんだっていう風に思いましたね確かにただ ct えばそうですねインドとかヨーロピアン系から離れた言語あとちょっと制度データを増やしても若干制度がわかりづらくて この辺は海苗の予知あり得ような風に言われていますねこれって実際にその68万時間のうちの英語は何時間分でとかってうちわけも出ているんですかただあったと思いますね 半分以上が確か英語でそんなにとプロットビルと日本語が一万時間くらいで少ないのだと10時間くらいしか10時間1時間しかないようなのもあるっていう風になってますね日本語は一万時間なんだなんかすごい制度いいっていうけど68万時間うちの1時1時間分しかデータはなかったんですねそうですねそんなもんなんだそんなもんって言っても全然多いんだろうけど一万時間分の日本語の音声のしかも教師ありってなるとでも他にもいろいろ実験してるんですけどマサラット説明していくと他に入力音声にノイズが持ってしまっても既存モデルよりロバストですっていうのが結果もありますあと既存の研究性化以外に商用の音声描き起こしサービスとかと比べてもそんなしくない制度もですよねっていうのも報告されていますとそれとは別にですねプロ人間のプロの描き起こしとも比べてみたときにそれにもかなり必要していますねっていうの結果も報告されていましたでここまで実験結果ですねノイズにも強いっていうのは確かにデベロッパーズ愛用でブログが書かれていてそれなんかわざわざオンライン会議の音声のものにセンプーキーの音を応えて合成してそれでベースモデルとミディアムとラージのモデルでなんかノイズにどれぐらい県路なのかみたいな実験とかされてましたね確か結果はベースだとセンプーキーの音入れたらちょっと下がっちゃうけどあとたからミディアムとかラージはなんかほとんど影響なかったっていうぐらいサービスを強くしてるみたいな感じで面白い結果でしたねだからエンジニアだとちょっとそういう公開されてるものに偽悪したくなるのはちょっと分かるなと思いますねなので結構いろんな実験結果でかなり制度高くかつなかなりロバスとってのが報告されていました一方でリミテーションとかフィーチャーワークっていうのもいくつが語られていますと今回先ほどデータセットの準備ってここで少し触れたんですけど学習れた基本の30秒ごとで学習していますとではミスパーがじゃあそれ長いオンスを処理するときにはどうしているかっていうとあれだとこれは内部に30秒ごとにスライドしながら処理するってことをやっていますとその時にアピームサーチとかヒュリスティックスクフワイク使持ちいてるんですけどここはまだまだ自然に繋いで長いオンスを書き起こしできるように改善のやちがありますよねというふうに言われていましたもう一個ですねまだ完璧じゃないんだなっていうふうに思った点として特に長いオンスでだと人間ならやらないような間違い書き起こしのテキストがループしたりなんか最初とか最後の内容を募集していたり存在明らかに存在しないような単語ができそうに現れるっていうようなことを報告されていてこの辺はよりすぐれたデコーディングが必要ですよねっていうふうに報告されていましたでまああとは細かいところだとモデルを開けてくちゃ今回かなりシンプルな延後だデコーダーとランスフォーマーですってところだったりデータ各庁も来てないですっていうところだったりあるのでその辺の改善だったりまた基礎の地獄教師あり学習とかと組み合わせるっていうのもおよ先としてはありですよねっていうふうに書かれていましたなるほどこれってそういえばOSSだからコード取ってきて回せますけどCPUとかでもベースモデルだったら周るみたいな結構軽いんですよね確かなんかそんな話だった気がするそうですねなんかそれぞれメモリの大きさかいてあって一番大きいのでもなんか中期がとかだった気がするのでR分にははいもちろん処理がちょっと遅くなっちゃうかなと思いますけどR分にはRのかなと思いますねGPU持ってきたらもっと早く回るってことですよねそしてそうですねはいもちろんその発だと思いますなるほどななんかTwitterであと見たのはM&MACであのリビルド宮川さんM&MACで3時間ぐらいの音声を文字をご指使用としたら結構なんか丸一日かかったみたいなシートされた気がしてますねそれがでもちょっとオッケーモデルだったのかなラジじゃなくてミリアムかベースみたいな話だったと思いますけど長い音源になったらCPUとかだったら全然時間かかるんだなっていうポイイですねなるほどなるほどそうですねはいありがとうございますでまあ以上含めてまとめに移りますとまあ最初に話したりまあウィスパーホーフな多言語のデータセットで真シンプルな延後が出行だベースのトランソーマモデルでマルチタスクの学習を行いましたと結果的に人間に引いてきする制度とロバスト性の音声に式の力を書くたびできましたっていうふうに報告されていますとでまた中途中もちょっと言ったんですけど私の感想としたりしてマフォーフのデータセット用意室それだけじゃなくてちゃんとできるだけって品質のデータっていうのは違いしていたりするところまたったり英語の書き方し以外にもたげんごの書き方越しだったりげんごの特定などいろんなタスクっていうのシンプルなセイクエストセイクエストの学組に落とし込んでスケーラブルなモデルを獲得しているっていう点がかなり公園として大きいのかなディフに感想として思いましたってところですねこれって特に何が凄かったかっていう意味で言うとゴミっぽいデータはちゃんと配置した上でかなり棒大な教師ありの音声データを使ったからっていう公園が結構サブンとしてでっかいんですかね従来研究とはそうですねやっぱりそれ大きいと思いますねまたそれってそのマルチタスクの学習をうまくシンプルな形に落とし込んでシンプルな変更なデーコードとランスフォーマーで学習しているっていうのが機構大きいんじゃないかなと思いますなんかモデルはそんなに対したことないふうに聞こえたんですけどいやモデルもちゃんとマルチタスクのっていうところで凄いやつなんだよっていうことなんですかねそうですねまたもこのモデルのアンキテクチャンだけで言えば割と結構簡単に実装できるんじゃないかなと思いますねそのマルチタスクのデータをうまく加工を正計するところが割と難しそうかなっていうふうに思いましたねあとあのなんか初めの方の話なんですけど気になったのはグーグルの100万時間の方で出会したビックエッセルでしたっけあれは制度もなんか言うほどよくなかったって話だったんですけどそっちのビックエッセルの方はそしたらデータ量はちゃんとあったのにモデルがなんかあんまり行けてなかったってことになるんですかねもっといろいろ違いはあると思うんですけどそうですね多分やっぱり強しなしだとちょっと限界があるのかなっていうのと結局そのファインチューニング先にオーバーフィッドしちゃっていうのがバカのビスパートのサブンとしてはかなり大きいんじゃないかなって思いますねまたは制度もそんなに悪い程度ではないと思うんですけど反応な色んなシーンのデータに今販壊して水論できるってみだと不強しわりで大体のデータでデータを用意して学習したビスパーに軍売が上がっているのかなと思いますねそんな感じなんですねこれまたベースとミリアムとラージーって言って結構使いやすい形でローカルマシンでも回せる形で提供してるくれてるからまたそこもなんかこうこんなけ話題に探出たっていうのは貢献してるんですかねスティブルディフィーションと一緒で姿勢の人たちも回しやすいという意味で結局そうですそのビックSSLこれまぁ公開されたとしてもその強しなしの状態で公開されたとしても自分で使うにはファインチューニングしなきゃできないですしファインチューニングされたものだとファインチューニング先のデータにオーバーフィットするっていう形になっているので完全にすぐ黒をして使えるウィスパーもかなり注目されているのかなと思いますねなるほどいやありがとうございますちょっとこれこの収録までに白金エンフェーム試しにやってみあの文字を越ししてみてすごいっていう話をここにそうやられたらいいと思ったらマニアーズなんでちょっと追加の宿題でやっとこうと思いますそうなんですよねちなみに今まで白金エンフェームは投稿するときにあの文字を越ししたワードクラウドをツイートにくっつけてたんですけどあれはずっとずっとというか一応公開されてる文字を越しのあのアジュールとAWSとGCPの文字を越しのAPIを使って比較して一番AWSのやつが使いやすかったので文字を越しの品質も結構どんぐりの精綺麗的な感じであるんですけど真指だったからそれ使ってたんですけど今回からはウィスパーで全部回したいなと思いますねそんなに違うんだったらということでめちゃ楽しみそうですねちょっとそれはぜひ見てみたいですねうんそうですよねやっとなんか今までのクラウドサービスねってやっぱしクラウドにデータを行くのでその社内の秘密の会話とかはやっぱり簡単にあげて文字を越ししようみたいなできなかったですけど今回これもローカルで回せるから社内用のなんかおもちゃツール作ってそこに投稿したらみんなギジロク文字を越しできるようみたいなまあラジュモデルで結構思いけどみたいなも含めてできるからこれなんていうんですかなんかこれみんなが求めてたやつですごい業務効率みたいな何ももっと使えると思ってもっと話題になると思ったんですけどなんか微妙にちょっと下微になってきますまた人盛り上がりした後にそうですねこれの理活用事例みたいなのめっちゃ楽しみにしてますねタイムラインにいっぱい出てくるのかなりすごいした大用のやちは広そうな気はしますねあとなんかこれちょっと関係ないんですけど結構似たようなタイミングでフェイスブックの研究開発部署がアランドディのところが作ったなんて読むんだろうデムカスV3かなちょっと読み方間違えてる気はしますけどそれその音源分離ができるっていうやつが出ててかなり綺麗にバンドの音とボーカルの音を切り分けたりとかできてたんですけどなんかそんなことももうかなり綺麗にできて文字をこしもちゃんとできるんだったら音声系のデータ基本的にも制発したと言っても過言ではないので終わって思ったりするんですけど会場への人たち的にはどうなんですかねいやどうなんですかね人僕も正直音声はほとんど触れてなかったので分からないとこれじゃあるんですけどあれも多い結構そして例えばウィスパーだとその中で明らかに離されてないタンが出てくるとかなんかループしてしまうとかそういったかなりなんかねぶかい問題そうなのでこの辺まだやっぱり改善の実際がまだまだあるのかなと思いますねうんそうですねデコーダーが改善されてもうちょっと長く学習とスイロンを行うような感じになってきたらまぁまたという間によい奴が出るんでしょうねそうですねはいかなり期待できると思いますやりがございましたちょっとぜひ早めに試してこんなにまあのAWSとかのAPIと違うっていうの比較したいですね自分もそうですねはい楽しみですねじゃあ結構作っと終わっちゃいましたがこんなところですかねではでは今回はこれで終わりたいと思いますありがとうございましたありがとうございました'
