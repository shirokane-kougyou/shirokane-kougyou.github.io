---
actor_ids:
  - asano
  - Hyperion_13
  - kim_junhyeong
audio_file_path: /audio/070.mp3
audio_file_size: 
date: 2023-05-29 00:00:00 +0900
description: LLM回！またまた辻さんと金さんからLLMについて教わりました！
duration: 
layout: article
title: 70. ２回目のLLM回！LLM研究プロジェクトの話＋最近気になったLLMのトピックについて
---
感想などは白金鉱業.FMのハッシュタグ [#白金鉱業fm](https://twitter.com/search?q=%23%E7%99%BD%E9%87%91%E9%89%B1%E6%A5%ADfm&src=typed_query) につぶやいてもらえるととても喜びます！  
匿名でのお便りも[google form](https://forms.gle/pRVNhjrhk8F88T228)にてお待ちしております！  
---
---
## 0:27~：ブレインパッドの「LLM/Generative AIに関する研究プロジェクト」
- LLM/Generative AIに関する研究プロジェクトの発信メディア
    -  ブレインパッド公式のプラチナデータブログ
        - 社内プロジェクト発足を公式発表： [LLM/Generative AIに関する研究プロジェクトを立ち上げます - Platinum Data Blog by BrainPad](https://blog.brainpad.co.jp/entry/2023/05/15/153006)
        - LLMブログ連載１回目の記事:[【連載①】大規模言語モデル（LLM）のビジネス利用に関して注意すべき点-LLMの使用許諾条件- - Platinum Data Blog by BrainPad](https://blog.brainpad.co.jp/entry/2023/05/16/153000)
    -  doors（特にビジネス適用の記事はこちら！）
        -  [社内文書に特化したChatGPT｜ファインチューニング実践編 | DOORS DX](https://www.brainpad.co.jp/doors/knowledge/01_chatgpt_fine_tuning_internal_documents/)
    -  [Open BrainPadのTwitterアカウント](https://twitter.com/Open_BrainPad)でも調査した論文について発表しています

## 06:07〜：ChatGPTのプラグイン
5/12に、有料版の「ChatGPT Plus」ユーザー向けに、Webブラウジング機能とサードパーティプラグインのベータ版が提供開始されました。早速いくつかのプラグインを試した金さんにお話を伺いました。
- [ブラウジング機能](https://openai.com/blog/chatgpt-plugins#browsing) → β版
            - Bing Chat
            - 検索 → クリック → コンテンツを読む
            - 回答のソースがわかるのでより信憑性のある会話ができる
- [Code interpreter](https://openai.com/blog/chatgpt-plugins#code-interpreter) → α版


## 24:00〜：プロンプトエンジニアリングの論文
[Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](https://paperswithcode.com/paper/plan-and-solve-prompting-improving-zero-shot)
- CoTのようにstep-by-stepで考えるのではなく、一度小さいタスクを洗い出してから順に実行するPlan-and-Solve Promptを提案した論文
- LLMも計画性がある思考の方が性能が出しやすい模様
https://blog.langchain.dev/plan-and-execute-agents/

## 30:36〜：インバーススケーリングロウ(クレーム)の論文
[An Inverse Scaling Law for CLIP Training](https://paperswithcode.com/paper/an-inverse-scaling-law-for-clip-training)
- 従来の認識：画像/テキストエンコーダの規模が大きいほど、トレーニングに必要な画像/テキストトークンのシーケンス長も同様に長くなり、その結果、大規模な計算リソースが必要となると考えられていた
- 「Inverse Scaling Law」の発見で分かったこと：エンコーダの規模が大きくなるほど、トレーニングに適用できる画像/テキストトークンのシーケンスの長さを逆に短くできるということが明らかになった
- 今後期待できること：CLIPのトレーニングが計算リソースが限られた環境でも可能となりフィールドに新たな進歩をもたらす可能性がある
- OpenBPのTwitterアカウントで共有した[WhisperをTPUとJAXで最適化したら70倍速くなった話](https://twitter.com/Open_BrainPad/status/1649210122797973504?s=20)

## 42:38〜：世界中でバズったDrag Your GAN
[Drag Your GAN: Interactive Point-based Manipulation on the
Generative Image Manifold](https://arxiv.org/pdf/2305.10973.pdf)
- ハンドルポイントとターゲットポイントをクリックするだけで、画像を生成。
- ライオンの口内の歯などの隠れたコンテンツも再現可能
- 馬の脚の曲げなどオブジェクトの剛性に従って変形することもできる